{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ced3838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d497a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def linear_probe(dataset):\n",
    "    #Load model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load('RN50', device)\n",
    "\n",
    "    #Load dataset\n",
    "    root = os.path.expanduser(\"~/.cache\")\n",
    "    if dataset == \"CIFAR10\":\n",
    "        train = CIFAR10(root, download=True, train=True, transform=preprocess)\n",
    "        test = CIFAR10(root, download=True, train=False, transform=preprocess)\n",
    "    elif dataset == \"CIFAR100\":\n",
    "        train = CIFAR100(root, download=True, train=True, transform=preprocess)\n",
    "        test = CIFAR100(root, download=True, train=False, transform=preprocess)\n",
    "    elif dataset == \"MNIST\":\n",
    "        train = MNIST(root, download=True, train=True, transform=preprocess)\n",
    "        test = MNIST(root, download=True, train=False, transform=preprocess)\n",
    "\n",
    "    def get_features(dataset):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
    "                features = model.encode_image(images.to(device))\n",
    "\n",
    "                all_features.append(features)\n",
    "                all_labels.append(labels)\n",
    "\n",
    "        return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "    # Calculate the image features\n",
    "    train_features, train_labels = get_features(train)\n",
    "    test_features, test_labels = get_features(test)\n",
    "\n",
    "    # Perform logistic regression\n",
    "    classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=0)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "\n",
    "    # Evaluate using the logistic regression classifier\n",
    "    predictions = classifier.predict(test_features)\n",
    "    accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "    return f\"{dataset} Accuracy = {accuracy:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58781ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:34<00:00,  1.49it/s]\n",
      "100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        10250     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15129D+05    |proj g|=  1.13516D+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.39793D+04    |proj g|=  1.14444D+02\n",
      "\n",
      "At iterate  100    f=  2.36020D+04    |proj g|=  2.49202D+01\n",
      "\n",
      "At iterate  150    f=  2.35885D+04    |proj g|=  1.92117D+00\n",
      "\n",
      "At iterate  200    f=  2.35879D+04    |proj g|=  4.71428D+00\n",
      "\n",
      "At iterate  250    f=  2.35878D+04    |proj g|=  4.08149D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "10250    274    292      1     0     0   1.279D-01   2.359D+04\n",
      "  F =   23587.782397848034     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "CIFAR10 Accuracy = 86.760\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:57<00:00,  1.40it/s]\n",
      "100%|██████████| 100/100 [01:15<00:00,  1.32it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       102500     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.30259D+05    |proj g|=  1.52442D+02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.00123D+05    |proj g|=  4.74049D+01\n",
      "\n",
      "At iterate  100    f=  1.00068D+05    |proj g|=  2.86478D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "*****    148    157      1     0     0   9.169D-02   1.001D+05\n",
      "  F =   100066.68951902445     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 16.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 Accuracy = 63.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "100%|██████████| 600/600 [04:26<00:00,  2.25it/s]\n",
      "100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        10250     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38155D+05    |proj g|=  1.23014D+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.73799D+04    |proj g|=  7.48579D+01\n",
      "\n",
      "At iterate  100    f=  2.66444D+04    |proj g|=  4.43989D+01\n",
      "\n",
      "At iterate  150    f=  2.65884D+04    |proj g|=  2.32177D+01\n",
      "\n",
      "At iterate  200    f=  2.65775D+04    |proj g|=  2.43566D+00\n",
      "\n",
      "At iterate  250    f=  2.65756D+04    |proj g|=  5.33320D+00\n",
      "\n",
      "At iterate  300    f=  2.65754D+04    |proj g|=  8.65665D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "10250    308    328      1     0     0   1.137D+00   2.658D+04\n",
      "  F =   26575.412240490539     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Accuracy = 95.690\n"
     ]
    }
   ],
   "source": [
    "print(linear_probe(\"CIFAR10\"))\n",
    "print(linear_probe(\"CIFAR100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d75890e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST: 95.69%\n",
    "#CIFAR100: 63.58%\n",
    "#CIFAR10: 86.76%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
